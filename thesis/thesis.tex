\documentclass[supercite]{HustGraduPaper}

\title{高性能异步编程框架的设计与实现}
\author{车春池}
\school{计算机科学与技术}
\classnum{校际交流1801}
\stunum{U201816030}
\instructor{邵志远}
\date{2022年5月10日}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{framed}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{xltxtra}
\usepackage{bm}
\usepackage{tikz}
\usepackage{tikzscale}
\usepackage{pgfplots}
\usepackage{listings}

\lstset{
 columns=fixed,       
 numberstyle=\tiny\color{gray},                       % 设定行号格式
 frame=none,                                          % 不显示背景边框
 backgroundcolor=\color[RGB]{245,245,244},            % 设定背景颜色
 keywordstyle=\color[RGB]{40,40,255},                 % 设定关键字颜色
 numberstyle=\footnotesize\color{darkgray},           
 commentstyle=\it\color[RGB]{0,96,96},                % 设置代码注释的格式
 stringstyle=\rmfamily\slshape\color[RGB]{128,0,0},   % 设置字符串格式
 showstringspaces=false,                              % 不显示字符串中的空格
 language=c,                                        % 设置语言
}

\tikzset{
  box/.style ={
    rectangle, %矩形节点
    rounded corners =5pt, %圆角
    minimum width =50pt, %最小宽度
    minimum height =20pt, %最小高度
    inner sep=5pt, %文字和边框的距离
    draw=blue %边框颜
  }
}

\pgfplotsset{compat=1.16}

\newcommand{\cfig}[3]{
  \begin{figure}[htb]
    \centering
    \includegraphics[width=#2\textwidth]{images/#1.tikz}
    \caption{#3}
    \label{fig:#1}
  \end{figure}
}
\newcommand{\sfig}[3]{
  \begin{subfigure}[b]{#2\textwidth}
    \includegraphics[width=\textwidth]{images/#1.tikz}
    \caption{#3}
    \label{fig:#1}
  \end{subfigure}
}
\newcommand{\xfig}[3]{
  \begin{figure}[htb]
    \centering
    #3
    \caption{#2}
    \label{fig:#1}
  \end{figure}
}

\newcommand{\rfig}[1]{\autoref{fig:#1}}
\newcommand{\ralg}[1]{\autoref{alg:#1}}
\newcommand{\rthm}[1]{\autoref{thm:#1}}
\newcommand{\rlem}[1]{\autoref{lem:#1}}
\newcommand{\reqn}[1]{\autoref{eqn:#1}}
\newcommand{\rtbl}[1]{\autoref{tbl:#1}}

\algnewcommand\Null{\textsc{null }}
\algnewcommand\algorithmicinput{\textbf{Input:}}
\algnewcommand\Input{\item[\algorithmicinput]}
\algnewcommand\algorithmicoutput{\textbf{Output:}}
\algnewcommand\Output{\item[\algorithmicoutput]}
\algnewcommand\algorithmicbreak{\textbf{break}}
\algnewcommand\Break{\algorithmicbreak}
\algnewcommand\algorithmiccontinue{\textbf{continue}}
\algnewcommand\Continue{\algorithmiccontinue}
\algnewcommand{\LeftCom}[1]{\State $\triangleright$ #1}

\newtheorem{thm}{定理}[section]
\newtheorem{lem}{引理}[section]

\colorlet{shadecolor}{black!15}

\theoremstyle{definition}
\newtheorem{alg}{算法}[section]

\def\thmautorefname~#1\null{定理~#1~\null}
\def\lemautorefname~#1\null{引理~#1~\null}
\def\algautorefname~#1\null{算法~#1~\null}

\begin{document}

\maketitle

\statement

\clearpage

\pagenumbering{Roman}

\begin{cnabstract}{异步I/O；协程；异步编程框架}

在大数据时代，随着互联网用户体量的高速增长，数据中心面对数量越来越庞大，频度越来越高
的数据访问，对更为高效的数据输入输出（下文简称I/O）技术方案的需求也日益增长。
在此背景下，传统服务端开发中使用的同步数据I/O模式由于线程阻塞问题逐渐在性能测试上达到瓶颈，
因此工业界和学术界正在探索和研究更为高效的异步I/O方案，希望以此来提高系统的整体性能。
同时，在系统并发编程领域，传统的多线程编程模式也慢慢展现出了它的弊端。近年来存储设备的性能
不断提高，现今某些高速存储设备进行一次I/O操作的开销已经能和一次线程切换的开销不分伯仲，
这意味着每进行一次线程切换系统就浪费一次I/O的时间。
面对线程切换开销重的现状，现代许多编程语言均提出了协程的概念，旨在提供一个更轻量，高效的并发编程模式。\par

  本课题基于Linux异步I/O接口io\underline{~}uring和协程设计并分别使用C++和Rust语言实现了两款高性能的异步编程框架\textbf{Kuro}和\textbf{Emma}。
同时，对此框架进行性能测试，实验结果验证了异步I/O模式和协程能实实在在地对系统性能产生积极的影响。\par

Kuro和Emma具备提供简单易用接口的能力，
使得上层应用开发者不需要了解异步I/O和协程的底层细节即可充分利用到两者的性能优势。
此外，在与当前开源生态中主流的几款异步编程框架的性能对比测试结果中发现，
Kuro和Emma具备顶尖的高效性能。\par

\end{cnabstract}

\begin{enabstract}{Asynchronous I/O, Coroutine, Programming framework}

In the era of big data, with the rapid growth of the number of Internet users, data centers
are faced with increasingly large and frequent data access, and the demand for more efficient
data input and output technical solutions is also increasing. In this context, the synchronous
data I/O mode used in traditional server development is gradually unable to perform performance
tests due to thread blocking problems.Therefore, the industry and academia are exploring and
researching more efficient asynchronous I/O solutions, hoping to improve the overall performance
of the system.
At the same time, in the field of system concurrent programming, the traditional multi-threaded
programming mode has gradually shown its drawbacks.In recent years, the performance of storage
devices has been continuously improved. Today, the overhead of one I/O operaion on some high-speed
storage devices is comparable to the overhead of on thread switching. This means that every time
the system is switched between threads, an I/O time is wasted. Faced with the current situation
of heavy thread switching overhead, many modern programming languages have proposed the concept
of coroutines, aiming to provide a lighter and more efficient concurrent programming model.\par

Based on the Linux asynchronous I/O interface io\underline{~}uring and coroutine design,
two high-performance asynchronous programming frameworks \textbf{Kuro} and \textbf{Emma} are implemented using C++ and Rust languages respectively.
At the same time, the performance of this framework is tested,
and the experimental results verify that asynchronous I/O modes and coroutines can actually have a positive impact on system performance.\par

Kuro and Emma
has the ability to provide a simple and easy-to-use interface,
so that upper-layer application developers do not need to understand the underlying details of
asynchronous I/O and coroutines to take full advantage of the performance advantages of both.
In addition, through the performance comparison test with several mainstream asynchronous programming frameworks in the current open source ecosystem,
it is proved that Kuro and Emma has top efficient performance.\par


\end{enabstract}

\tableofcontents[level=2]
\clearpage

\pagenumbering{arabic}

\section{绪论}

本章我们首先介绍了当前并发系统编程领域面临的挑战和技术发展趋势，然后分析了异步I/O和协程
的产生及发展现状，接着介绍了国内外针对异步编程框架的相关研究工作，最后对本文的主要研究内容
及工作意义作了具体说明。

\subsection{课题背景}

\subsubsection{研究背景和趋势}
\subsubsubsection{同步I/O与异步I/O}
Linux 平台上的I/O模型经历了几个发展阶段：阻塞，非阻塞\cite{block-io-java}，多路复用\cite{multiplex-linux}，
信号驱动\cite{signal-linux}，异步\cite{async-io-linux}。
其中前四种均属于
同步I/O模式。同步I/O的共性是对于调用过程的双方：用户程序和硬件设备，它们之间流动的数据需要经过
操作系统内核进行同步，完全准备好后，才能复制到用户空间，用户程序才能继续往下执行。而数据等待的过程
会阻塞用户线程，直到整个I/O调用链路完成。线程阻塞问题导致了同步I/O的低效，因此异步I/O作为一个高性能
解决方案被提出，它的特点是用户程序发起I/O请求后，不需要进行任何的等待，可以从容地转向处理其他任务，
然后在合适的时机检查数据传输是否完成，再对该数据进行相应处理。异步I/O模式解决了线程阻塞\cite{thread-bloking}的问题，
提高了资源利用率。\par

异步I/O通常需要操作系统内核提供支持。Linux 平台存在原生的异步I/O接口：libaio\cite{endo2020comparative}，
但其存在复杂难用，性能低
等问题，因此Linux在很长一段时间内处于缺少异步I/O接口的状况。这导致系统存储领域在很多时候会采用
绕过内核（kernel bypass\cite{chen2018survey}）作为高性能解决方案。终于，在5.1版本，Linux新增了io\underline{~}uring特性\cite{seong2020improving}，
提供了一个简单易用，高性能的异步I/O接口。并且在随之而来的性能评估结果中，io\underline{~}uring 展现出
了足够强大的性能潜力。因此，基于io\underline{~}uring的学术研究和工程变革势在必行。\par

\subsubsubsection{线程与协程}
在介绍协程之前，先来分析一下协程产生的原因和要解决的问题。\par

在传统Linux并发编程领域中，通常使用多线程作为并发模型的基础。操作系统内核为每个线程分配独立的栈空间，
使得每个线程可以独立地并行执行，能成倍提高程序运行的效率。同时，每个线程可以占据独立的CPU核，
充分利用现代CPU的多核架构\cite{hong2011efficient}。想象一下，一个用户程序运行在一个拥有4核的CPU芯片上，创建4个线程，
每个核执行单个线程任务，则程序的运行效率将是单线程的4倍。\par

但线程的问题是，线程与线程之间切换的开销巨大\cite{david2007context}。进行线程切换时需要进行以下步骤：

\begin{enumerate}
  \item 从用户态进入内核态；
  \item 内核保存用户线程的上下文；
  \item 内核恢复下一个线程的上下文；
  \item 从内核态回到用户态。
\end{enumerate}

由此可以看出，线程切换需要经历特权级的切换和上下文的保存与恢复，这会带来巨大的\textbf{显式开销}；
此外，线程切换同时会带来缓存失效，分支预测\cite{smith1998study}失败等\textbf{隐式开销}。\par

过去几年存储设备快速发展，如今一些高端设备，比如Intel Optane\cite{izraelevitz2019basic}，延迟已经降低到和线程切换所耗费的时间一个数量级上了。
这意味着：每进行一次线程间的切换，整个系统就浪费一次进行I/O操作的机会。\par

因此为了解决线程间切换开销大的问题，协程（coroutine）的概念被提出来，它被称为\textbf{用户态线程}。

协程一词最早出自于上个世纪的程序员马尔文·康威，关于协程的论文\cite{paper1}最早在
1963年发表。协程可以被理解为是一个可以随时挂起和恢复运行的函数。它可以通过\textbf{yield}
来让出当前CPU，然后运行其他协程；它也可以通过\textbf{resume}来恢复执行。当一个协程被恢复的时候，
它会从上次yield调用的位置继续执行。协程和线程类似，属于一种并发编程模式。\par

协程具有以下特点：

\begin{itemize}
  \item 类似于用户态的线程，属于线程之外的另一种并发模型；
  \item 可以在执行中途挂起和随后恢复；
  \item 不像线程一样拥有独立的系统栈空间，因此无法使用多核实现真正的并行；
  \item 协程间切换不需要特权级切换，也不需要整个用户上下文的切换，因此切换开销比线程小许多。
\end{itemize}

协程可以被理解为能挂起和恢复的函数。当创建了多个协程时，从用户视角来看可以认为是多个协程在并发运行，
但从内核视角来看，实际上是多个协程在串行执行，因为它们只用到一个CPU核，
因此协层做不到真正意义上的并行\cite{bogaerts2010concurrency}。\par

那么什么时候该用线程，什么时候该用协程呢？\par

对于计算密集型任务，多线程架构能充分利用多核，使得程序运行效率成倍提高，这时候使用线程；
对于I/O密集型任务，程序大部分时间都在等待I/O数据，CPU负担不重，而协程切换开销小，因此这时候该用协程。
在实际应用中，很多时候需要根据具体场景，结合两者使用。\par

总结对比一下线程和协程：

\begin{generaltab}{线程vs协程}{tbl:hmm}
  \begin{tabular}{c|ccc}
    \toprule
    -- & 线程 & 协程 \\
    \midrule
    是否支持并发 & 是 & 是 \\
    是否支持多核 & 是 & 否 \\
    是否涉及内核态 & 是 & 否 \\
    切换开销 & 大 & 小 \\
    适用场景 & 计算密集型 & I/O密集型 \\
    \bottomrule
  \end{tabular}
\end{generaltab}

\subsubsection{异步I/O和协程的结合}
尽管异步I/O在理论上拥有比传统同步I/O更好的性能优势，但同时其带来的编程上的复杂性也是不容忽视的一部分。
如何降低异步I/O带来的编程复杂度，是软件开发者必需考虑的问题之一。针对这个问题，工业界提出了一个
解决方案：通过\textbf{协程}与异步I/O结合进而降低编程难度。\par

当协程和异步I/O结合后，可以让协程A在发起I/O请求后挂起，然后调度运行其他协程。等待I/O操作完成后，
再恢复运行协程A，这样就可以充分利用CPU资源。协程的运作模式和异步I/O浑然天成。\par

\subsubsection{面临的问题和挑战}
\textbf{高性能高可用的异步编程框架}。前两小节介绍的io\underline{~}uring和协程均为较原始，较底层的概念，
两者对于不熟悉操作系统和编程语言底层的一般应用软件开发者而言，无论是在理解原理上还是在工程实践上
都存在较高难度。在现代的软件开发领域，分层设计已成共识，因此上层应用开发者需要一个易用的
\textbf{异步编程框架}。通过该框架，他们可以在不了解io\underline{~}uring和协程底层原理的情况下
充分利用到两者的高性能特点，从中收益。\par

这种异步编程框架，在不同的编程语言里面存在不同称呼，比如在C++语言里面它被称为\textbf{协程库}，
在Rust语言里面被称为\textbf{异步运行时}\cite{rosendahl2017green}。
但是不管在哪种编程语言里面，它的存在意义是一致的：
对底层操作系统的异步I/O接口和编程语言层面的协程进行统一封装，向上层应用程序的构建提供简单易用的
异步编程接口。\par

遗憾的是，目前的系统编程领域的软件生态对于上述的异步编程框架暂时留有较大一片空白。尽管存在一些相关
的开源项目，但各自在实际应用中都暴露了或多或少的不足。因此我们分别基于Rust语言\cite{klabnik2019rust}和C++语言设计并实现了
一个异步编程框架，对底层io\underline{~}uring和协程进行了封装，向上层应用开发提供了简单易用的编程接口，
希望可以借此解决传统并发编程和系统编程中的一些痛点。\par

\subsection{国内外研究现状}

\subsubsection{Tokio：Rust异步运行时}
在Rust语言开发领域内，上述的异步编程框架在这里被称为\textbf{异步运行时}（Async Runtime）。
Tokio\cite{tokio.org}是目前Rust社区里最成熟，也是为数不多广泛应用于工业界研发的Rust异步运行时。
Tokio 现已推出1.0版本，它提供了基于多线程池的协程调度器和基于epoll\cite{gammo2004comparing}的异步网络编程接口。\par

Tokio优点是具有轻量，安全可靠的特点，它可以减少应用程序的崩溃和增加线上系统的稳定性；
同时，它也存在缺点：相比与在网络编程方面的优秀表现，Tokio在存储领域的表现则相形见绌，因为它在文件I/O上
使用的是同步I/O模式，而在上文已经提到过同步I/O的低效。\par

\subsubsection{Libco：C++协程库}
在C++语言开发领域内，上述的异步编程框架在这里被称为\textbf{协程库}。
在C++20之前，C++语言本身不支持协程，开发者们通常通过第三方协程库来获得协程的底层支持。
其中，微信团队开源的\textbf{libco}\cite{libco.org}项目就是知名度较高的一个。libco是微信后台大规模使用的
C/C++协程库，自从2013年开始到如今仍稳定运行在微信后台的大规模服务器集群上。\par

微信\cite{montag2018multipurpose}作为支撑上亿用户的国民级软件，它所使用的协程库libco无疑在性能，稳定性上拥有非常优秀
的表现，但它仍然存在一定的缺点。一是libco对使用者的要求较高，一般开发者无法很好地驾驭；
二是C++20后在编程语言层面提供了协程支持\cite{belson2020c++}，而C++20官方的协程标准和libco不兼容，
因此libco的使用价值会逐渐变小。\par

\subsubsection{Goroutine: Go语言原生协程}
说到协程，就不得不提一下Go语言\cite{meyerson2014go}从诞生之际就根植于其基因之中的\textbf{Goroutine}：Go语言原生协程\cite{prabhakar2011concurrent}。
Goroutine是Go语言中最为基本的执行单元，它本质上是Go语言原生的一种协程实现。
Go语言中的协程，也就是Goroutine，具有着易于编程的特点，只需要一行代码则可以生成一个协程，
并且开发者不需要关心其中的底层细节。\par

Goroutine最大的优点是用法灵活且方便。可以说Go语言逐渐成为国内大厂后端开发的首选语言，
Goroutine功不可没。然而，Goroutine由于语言本身的垃圾回收机制\cite{sibiryov2017golang}，在性能上相比Rust/C++等
零成本开销语言稍逊一筹\cite{keskiniemi2022measuring}。同时，Go语言向开发者隐藏了底层协程调度等细节，也就意味着它剥夺了开发者
根据业务场景进行针对性优化的能力，而Rust/C++则能做到这一点。\par

\subsubsection{Node.js：跨平台的JavaScript运行时环境}
\textbf{Node.js}\cite{tilkov2010node}是一个开源的，跨平台的\textbf{JavaScript}\cite{crockford2008javascript}（简称JS）运行时环境，它使得我们可以在浏览器之外
的环境，比如Linux，运行V8引擎。Node.js向JS使用者提供了一系列异步的I/O原语，
使得JS代码不会在执行I/O操作受到阻塞。\par

Node.js性能很好，基于Node.js搭建的服务器程序能支持同时与数千个服务端进行并发连接。
同时，Node.js具备庞大的生态支持，数百万的前端开发者可以通过Node.js，无需学习新的编程语言，
即可进行服务端程序的开发。然而，Node.js依然存在缺点，其中一个是JS本质上是解释性语言，
底层框架对JS代码进行解析会带来不俗的性能开销。\par

\subsection{课题研究的意义，内容和目标}

\subsubsection{课题研究的意义}
本课题将围绕异步I/O和协程进行，目标是基于身为异步I/O接口之一的io\underline{~}uring和协程
设计并实现一款高性能的异步编程框架，
有助于解决传统并发编程中同步I/O阻塞线程和线程切换开销大的问题，存在能验证异步I/O和协程可以带来
性能提升的理论意义和向应用软件开发者提供简单易用，高性能的异步编程接口的实用意义。\par

\subsubsection{课题研究的内容}
\begin{enumerate}
  \item Linux io\underline{~}uring的底层原理和调用规范；
  \item Rust/C++协程的底层原理和编程范式；
  \item 构思设计如何结合io\underline{~}uring和协程实现异步编程框架；
  \item 将(3)中的设计落实到工程实践上，完成代码实现；
  \item 基于(4)中实现的异步编程框架进行性能测试，验证异步I/O和协程带来的性能优势。
\end{enumerate}

\subsubsection{课题研究的目标}
探索一种结合io\underline{~}uring和协程的编程模式，并基于该模式完成异步编程框架的设计与实现。
通过异步编程框架，为应用软件开发者提供构建高性能应用程序的平台，最终系统实现的目标为：

\begin{enumerate}
  \item 封装底层io\underline{~}uring和协程概念；
  \item 提供Linux上文件和网络异步I/O的外部接口；
  \item 在性能表现上比当前大部分主流的开源框架比如Tokio，Go更为优秀。主要参考以下指标：
    \begin{enumerate}
      \item 文件读写速度；
      \item 网络服务吞吐量。
    \end{enumerate}
  \item 安全，稳定，可靠。
\end{enumerate}


\subsection{论文结构}
本论文共分为五个章节：\par

第一章，首先介绍异步编程框架的研究背景，研究现状和国内外知名的几个相关开源项目，
接着引出课题研究的意义和内容，最后说明课题研究的目标。\par

第二章，将以异步I/O和协程为基点，对io\underline{~}uring，有栈协程和无栈协程等背景技术进行介绍。\par

第三章，根据课题需要，将首先确定异步编程框架的功能需求，然后介绍系统的整体架构设计，
最后对系统的各个模块进行详细分析。\par

第四章，将针对系统设计中的每个功能模块，详细介绍其具体实现方法。\par

第五章，对实现完成的异步编程框架，进行性能测试，并完成对测试结果的讨论和分析。\par

第六章，将会对整个异步编程框架的实现过程进行总结，总结其已完成的功能和在性能上达到的效果，
并展望下一步的工作开展方向。\par

\section{背景技术概述}
\subsection{同步I/O与异步I/O}
Linux平台上的I/O操作从场景视角看大致可以分为两种：网络I/O和文件I/O，下文的讨论对其不予区分。\par

一个I/O操作可以从发起者和处理者角度分成两个过程:
\begin{enumerate}
    \item 发起者发起I/O请求；
    \item 处理者处理I/O请求。
\end{enumerate}\par
而同步I/O和异步I/O的区分标准是：在整个I/O操作过程中，是否存在发起者和处理者中某一方或双方
因需要同步步调而导致的阻塞现象。如果存在，则为同步I/O，反之为异步I/O。
在Linux的语境下，发起者通常指用户线程，处理者通常指操作系统内核。\par

Linux上存在五种I/O模型：阻塞I/O，非阻塞I/O，I/O复用，信号驱动I/O，异步I/O。
其中前四种属于同步I/O模型，第五种属于异步I/O模型。下面将会对这五种I/O模型进行详细分析。\par

\subsubsection{阻塞I/O模型}
用户线程发起I/O请求后，进入内核态，内核线程请求硬件设备，等待数据准备好后，内核线程将数据拷贝到用户态空间，
然后返回到用户态，用户线程得以继续执行。在此场景用户线程在执行流进入内核态到返回到用户态之间的这段时间内，
一直处于阻塞状态，因此阻塞I/O属于同步I/O模型。\par

典型例子：Linux上的read(2)，write(2)系统调用和配置为阻塞的套接字。\par

\cfig{block-io}{0.5}{阻塞I/O模型}

\subsubsection{非阻塞I/O模型}
用户线程发起I/O请求后，进入内核态，内核线程检查数据准备状态，这时候会有两种情况：
\begin{enumerate}
  \item 数据未就绪，这时候内核会返回一个错误信号给用户线程，用户线程收到错误信号，需要再次发起系统调用进入内核；
  \item 数据已就绪，内核将缓冲区数据拷贝到用户态空间，返回到用户态。
\end{enumerate}

在此场景，用户线程需要不断轮询内核，直到内核执行上面第二种操作，本质上用户线程在轮询的过程中也是处于
阻塞状态，因此非阻塞I/O也属于同步I/O模型。\par

典型例子：Linux上配置为NONBLOCK的套接字。\par

\cfig{nonblock-io}{0.5}{非阻塞I/O模型}

\subsubsection{I/O复用模型}
多个用户线程注册I/O请求到一个复用器上，然后使用一个用户线程监听该复用器。用户线程提交监听请求后，
进入内核态，内核遍历复用器上的I/O请求并请求硬件设备。当多个I/O请求中某个请求的数据就绪后，
内核将其拷贝到用户态空间，然后返回到用户态，用户线程继续执行。在此场景，用户线程在发起系统调用进入内核后
到返回到用户态之间的这段时间内，一直处于阻塞状态，因此I/O复用依然属于同步I/O模型。\par

I/O复用的好处在于可以通过一个用户线程的阻塞换取多个用户线程的非阻塞，获得整体上的性能提升。Linux 上的
select, poll, epoll等机制就是典型的I/O复用模型\par

典型例子：Linux上的select，poll，epoll机制。\par

\cfig{io-multiplex}{0.7}{I/O复用模型}

\subsubsection{信号驱动I/O模型}
信号驱动I/O模型通常用于Linux上的网络编程。用户线程通过sigaction系统调用在某个套接字（socket）上
注册信号处理函数，注册完成后返回用户态，此时用户线程不阻塞。与此同时，内核线程请求硬件设备，
当套接字上有数据报准备好时，向用户线程递交一个SIGIO信号。用户线程收到信号后，调用信号处理函数进行真正
的I/O请求（例如recvfrom(2)），此时会重新进入内核态，内核线程拷贝数据到用户态空间后，再回到用户态，
用户线程继续执行。用户线程在第二次进入内核态到再次回到用户态之间的这段时间内，一直处于阻塞状态，
因此信号驱动I/O还是属于同步I/O模型。\par

信号驱动I/O的好处在于用户线程第二次进入内核态时，套接字上已经有数据报到达了，内核线程这时候只需要做
数据拷贝动作而不需要等待，节省了等待数据的时间。\par

典型例子：Linux上的sigaction系统调用。\par

\cfig{signal-driven}{0.7}{信号驱动I/O模型}

\subsubsection{异步I/O模型}
以上四种I/O模型都属于同步I/O，共同特点是它们都存在某个时间段内的阻塞现象。\par

异步I/O在整个I/O操作过程中不存在阻塞现象。用户线程通过系统调用发起I/O请求后，首次进入内核态，
内核线程收到请求后进行处理，然后不做任何等待直接返回到用户态，用户线程继续执行。
当内核等待数据就绪并完成数据拷贝后，会通过某种方式通知用户。用户线程收到通知后，便可从容地处理数据。\par

异步I/O的好处是对于用户线程来说，整个I/O操作过程不存在任何阻塞现象，CPU资源得到充分的利用。\par

典型例子：Linux上的io\underline{~}uring特性。\par

\cfig{async-io}{0.7}{异步I/O模型}

\subsection{Linux io\underline{~}uring}

\subsubsection{旧时代的异步I/O接口：AIO}
在io\underline{~}uring之前，Linux平台存在原生的异步I/O接口：AIO，但AIO的使用存在诸多限制：

\begin{enumerate}
  \item 最大的限制在于AIO仅支持无缓冲的I/O访问，而无缓冲的限制导致AIO接口在大部分场景下都不可用。
    对于正常的带有缓冲的I/O访问来说，AIO接口的底层运作方式依然是同步的。
  \item 尽管AIO接口的使用者满足了所有使得I/O操作异步的条件，有时候它依然不以异步的方式进行运作。
    比如如果需要元数据来执行I/O操作，那么该I/O请求会被阻塞。
  \item API设计不当，AIO接口的实现中存在较多对用户程序来说不需要的内存拷贝，这导致性能受到影响。
\end{enumerate}

在很长一段时间内，Linux内核开发者们为了解决上述的第一个限制煞费苦心，但依然没有得到令人满意的结果。
与此同时，伴随着延迟达到10毫秒以下的高IOPS硬件设备的出现，AIO接口开始显得力不从心了。对于这些高速设备来说，
Linux内核接口的低效反而成为了它们发挥极致性能的拖油瓶。\par

最重要的是上述限制导致AIO接口在很多场景下都不可用，因此在很长一段时间内Linux平台都处于缺少异步I/O接口
的状况，这给应用开发者带来了很大的困扰。即使开发者们可以在用户态通过线程池来模拟异步I/O的实现，
但这终归不是一个根本的解决办法。\par

Linux社区开发者们最初的想法是尝试改进AIO接口，并且持续了一段不短的时间，原因是：

\begin{enumerate}
  \item 如果有办法改善和优化现有的接口，会是相对于提供一个新接口的更优解。开发新接口不仅仅需要
    接口开发者投入精力，还需要社区对其进行各方面的审核和最终批准，这无疑是一项艰巨且漫长的任务。
  \item 对于应用开发者而言，新接口意味着他们要重新对应用程序进行兼容性适配，而扩展已有接口则只需要
    他们进行微小的改动。
\end{enumerate}

但是最终Linux社区的内核开发者们还是选择了设计并实现一个新的接口，以此来填补Linux平台上异步I/O接口的欠缺。
原因是：

\begin{enumerate}
  \item AIO接口存在三个系统调用，对多个系统调用的修改需要添加新的系统调用来传递信息，最终会导致
    代码复杂性增高和可维护性变低，而且这仅仅解决了AIO接口的其中一个较为突出的问题。
  \item 修改AIO接口会引入新的问题（bug），或者会使得现有问题变得更加严重，比如会使得现有API变得复杂，难以使用。
\end{enumerate}

以上种种因素使得Linux社区迎来了他们日思暮想的新时代的异步I/O接口。
io\underline{~}uring，于Linux 5.1版本开始提供，统一了整个Linux平台上的异步I/O框架。\par

\subsubsection{io\underline{~}uring设计目标}
在Linux开发者们开始设计并代码实现io\underline{~}uring之前，他们设定了新接口的设计目标：

\begin{enumerate}
  \item 易于使用，难以滥用；
  \item 可扩展的，该接口不仅仅用于块存储，还可用于网络和非块存储；
  \item 功能丰富；
  \item 高性能。
\end{enumerate}

尽管上述目标之间存在互斥的现象，但开发者们以此为行动纲领开发了io\underline{~}uring接口。\par

\subsubsection{io\underline{~}uring架构}
io\underline{~}uring架构大致如下图：\par

\cfig{io-uring}{0.8}{io\underline{~}uring架构图}

io\underline{~}uring使用\textbf{共享内存}来实现内核态和用户态之间的信息交换。\par

每个io\underline{~}uring实例里包含两个\textbf{环形缓冲区}，这两个环形缓冲区都实例化在共享内存里面，
在用户态和内核态之间共享，分别是：

\begin{enumerate}
  \item 提交队列（Submission Queue，简称SQ），用于用户提交I/O请求和内核获取I/O请求；
  \item 完成队列（Completion Queue，简称CQ），用于内核提交I/O完成事件和用户获取I/O完成信息。
\end{enumerate}

提交队列和完成队列均为单生产者单消费者模型，容量大小为2的幂次方，同时支持无锁并发，内部通过内存屏障技术实现状态同步。\par

io\underline{~}uring中有两个基本操作：提交I/O请求和通知I/O完成事件：
\begin{enumerate}
  \item 对于提交I/O请求操作来说，用户线程是生产者，它在提交队列尾部推入I/O请求；
    Linux内核是消费者，它从提交队列头部弹出一个I/O请求，然后递交到内核线程中进行处理。
  \item 对于通知I/O完成事件操作来说，Linux内核是生产者，它在完成队列尾部推入I/O完成事件；
    用户线程是消费者，它从完成队列头部弹出I/O完成事件，以此得知之前提交的I/O请求已经完成。
\end{enumerate}

io\underline{~}uring这种请求方式的优点在于：赋予用户程序批处理I/O请求的能力，并且仅需要进行一次系统调用。
用户程序可以将一系列I/O请求提交到提交队列后，再进行系统调用一次提交给内核；同样，用户程序也可以
一次性检查完成队列，对已完成的I/O事件进行统一处理。\par

同时，io\underline{~}uring的整个I/O操作过程是完全异步的，用户完全可以在提交I/O请求后放心地去执行其他任务，
而不用任何等待；当I/O操作完成时，内核将更新完成队列，用户可以在合适的时机检查完成队列，从而得知之前提交的
I/O请求已经完成。\par

\subsubsection{io\underline{~}uring数据结构}
io\underline{~}uring分别使用\textbf{SQE}（Submission Queue Entry，提交队列条目）和\textbf{CQE}（Completion Queue Event，完成队列事件）
来描述I/O请求和I/O完成事件。这两个数据结构同时也分别是提交队列和完成队列中元素的数据结构。\par

% CQE数据结构：
%
% \begin{lstlisting}
%   struct io_uring_cqe {
%     __u64 user_data;
%     __s32 res;
%     __u32 flags;
%   };
% \end{lstlisting}
%
% \begin{itemize}
%   \item user\underline{~}data字段来自用户程序提交的I/O请求，内核不会对该字段进行任何修改，
%     仅仅是简单地从SQE里拷贝到CQE。该字段通常用于标识当前CQE对应于哪个I/O请求。
%   \item res字段中存放I/O请求的结果，在大部分情况下它等同于同步I/O中系统调用的返回值。举个例子，
%     对于类似于read(2)的读操作，如果该I/O请求成功了，res将会是完成传输的字节数；如果该I/O请求
%     出现异常，res将会是内核给出的错误码。
%   \item flags字段可能携带本次I/O操作携带的元数据，通常用于io\underline{~}uring中的高级用法。
% \end{itemize}
%
% SQE数据结构（省略某些字段）:
%
% \begin{lstlisting}
%   struct io_uring_sqe {
%     __u8 opcode;
%     __u8 flags;
%     __u16 ioprio;
%     __s32 fd;
%     __u64 off;
%     __u64 addr;
%     __u32 len;
%     __u64 user_data;
%     ...
%   };
% \end{lstlisting}
%
% \begin{itemize}
%   \item opcode字段描述了当前I/O请求的类型，比如类似read(2)的读请求的操作码为
%     IORING\underline{~}OP\underline{~}READ。
%   \item ioprio字段指示当前I/O请求的优先级。
%   \item fd字段表示一个文件描述符，可以是文件操作中的文件描述符，也可以是网络编程中的套接字。
%     比如，提交读请求的时候该字段应设为目标文件的文件描述符。
%   \item off字段在读操作中表示文件偏移量。
%   \item len字段在读操作中表示读取字节数的最大值。
%   \item user\underline{~}data字段是用户程序为当前I/O请求指定的标识，该字段会原封不动地被拷贝到
%     CQE中。当用户程序从完成队列中获取I/O完成事件时能通过该字段对应上相应的I/O请求。
% \end{itemize}
%
% 提交队列和完成队列均为无锁数据结构，这意味io\underline{~}uring支持多个用户线程并发地进行提交I/O请求
% 和收割I/O完成事件。io\underline{~}uring内部通过内存屏障技术保持并发时的数据一致性。\par

\subsubsection{io\underline{~}uring用户接口}

io\underline{~}uring向用户程序提供了三个系统调用：io\underline{~}uring\underline{~}setup，
io\underline{~}uring\underline{~}register和io\underline{~}uring\underline{~}enter。\par

io\underline{~}uring\underline{~}setup用于：

\begin{itemize}
  \item 初始化io\underline{~}uring实例和设置上下文环境；
  \item 创建提交队列SQ和完成队列CQ；
  \item 返回给用户程序一个文件描述符fd，后续与io\underline{~}uring相关的操作都在该fd上进行。
\end{itemize}

任何使用io\underline{~}uring的程序都应该从这个系统调用开始，完成环境初始化的工作。\par

io\underline{~}uring\underline{~}register用于：
\begin{itemize}
  \item 在io\underline{~}uring实例中注册文件；
  \item 在io\underline{~}uring实例中注册缓冲区。
\end{itemize}

该系统调用通常用于性能优化，注册文件或者缓冲区可以让内核长期持有对文件或缓冲区的引用，提高I/O处理的效率。\par

io\underline{~}uring\underline{~}enter用于：
\begin{itemize}
  \item 提交新的I/O请求；
  \item 收割已完成的I/O事件。
\end{itemize}

用户往提交队列推入了新的I/O请求后或者从完成队列中获得了已完成的I/O事件后，可以通过该系统调用告知内核有新的I/O请求到达了
或有已完成的I/O事件被收割了，内核会随之更新内部状态，维持两个队列的生产--消费平衡。\par

\subsubsection{liburing库}
从上面的分析可以感受到，即使io\underline{~}uring已经在API易用度上下了很大功夫，较之AIO接口简单易用许多，
但在实际使用过程中依然存在许多底层和细节的问题需要考虑，比如共享内存的映射。因此，io\underline{~}uring
的主要开发者Jens Axboe同时编写了一个用户态的库，名为\textbf{liburing}，
对io\underline{~}uring相关的一些底层细节
进行了封装，向用户程序开发者提供了更加简洁易用的API。\par

本课题中的项目实现也使用了liburing作为依赖库。\par

\subsection{有栈协程与无栈协程}
许多现代编程语言均支持了协程，其中包括Rust，C++，Go，JavaScript。
协程可以分为\textbf{有栈协程}和\textbf{无栈协程}，其中Rust，C++ 20，JavaScript中支持的是无栈协程，
而Go，C++第三方库libco中支持的是有栈协程。\par

有栈协程和无栈协程可以通过判断其是否存在\textbf{调用栈}来进行区分。\par

协程的调用栈类似于函数的调用栈。之前提到协程可以挂起和恢复，那么协程是如何在恢复之时从挂起点继续运行的呢？
这时候调用栈就派上用场了。函数的调用栈用于保存函数参数，返回地址等信息，而协程的调用栈则是用于保存协程的上下文。
当有栈协程恢复的时候，从调用栈中恢复上下文，即可从挂起点继续运行了。\par

而无栈协程没有调用栈，那么它是怎么保存上下文的呢？无栈协程底层通过状态机实现，当无栈协程挂起时，
它的上下文状态会保存在堆空间上；而当无栈协程恢复时，从堆空间读取上次挂起的状态，然后更新状态，再次挂起...
直到最后一次恢复时，读取的状态为结束，整个无栈协程退出。\par

总结对比一下有栈协程和无栈协程：

\begin{generaltab}{有栈协程vs无栈协程}{tbl:hmm}
  \begin{tabular}{c|ccc}
    \toprule
    -- & 有栈协程 & 无栈协程 \\
    \midrule
    是否存在调用栈 & 是 & 否 \\
    上下文保存点 & 调用栈 & 堆 \\
    底层实现原理 & 模拟函数调用 & 状态机 \\
    典型例子 & Goroutine，libco & Rust，C++ \\
    \bottomrule
  \end{tabular}
\end{generaltab}

\subsection{Rust语言中的协程}
早期的Rust语言曾支持一个被称为\textbf{绿色线程}的有栈协程实现，但在0.7版本之后便废弃了。
原因是如果Rust要支持绿色线程这样的机制，语言本身需要在运行时层面引入非常多的依赖，
而这种依赖对于不使用绿色线程的代码来说单纯是一种负担。Rust的目标是构建一门零成本抽象的语言，
不允许语言运行时层面存在不必要的开销，因此绿色线程最终被删除。\par

随后，Rust尝试采用无栈协程的方案。终于在2018版本中，Rust稳定了async/await语法，这标志着Rust
在协程和异步编程上的标准达到了统一。可以说，Rust的协程方案是现代编程语言中最为完美的。\par

值得一提的是，在Rust语言中，通常不强调“协程”的概念，往往通过“异步任务”表示协程。
在Rust中使用协程被称为“异步编程”。Rust异步编程主要涉及4个组件：Future，Executor，Waker和Reactor。
在本节中，将主要通过这些组件介绍Rust异步编程的概念和原理。\par

\subsubsection{Future}
\textbf{Future}是Rust异步编程中最为核心的概念，它表示一个将来值，这个值可能现在无法获得，
需要等到将来某个事件发生了才能获得。\par

Future中有且仅有一个\textbf{poll}方法，该方法需要传入一个\textbf{Context}类型的参数，
该参数表示该Future的上下文环境，返回值存在两种情况：

\begin{enumerate}
  \item Ready(value)，可以获得该Future的值value；
  \item Pending，该Future的值还未准备好。
\end{enumerate}

前面提到协程的特点是支持挂起和恢复。那么回到Rust里面的Future，当调用一个Future上的poll方法后，
返回值如果是Pending，那么意味着这个Future的值还没准备好，这时候需要挂起；当在适当时机恢复后，
再去调用这个Future的poll方法，这时候返回Ready，就可以获得该Future的值了，代码得以继续执行下去。
这样Future就和协程的概念对应上了。\par

这里出现一个问题：这里的挂起和恢复操作谁来执行呢？答案是将会在下文介绍的执行器Executor。\par

Future在Rust中是以接口的形式定义的，当一个结构体A实现了Future接口，则可以称A为一个Future。
Future具有组合性，可以将多个叶子Future组合成一个大Future。比如\rfig{future}：

\cfig{future}{0.4}{组合Future}

\rfig{future}的大Future由5个子Future组成，其中B，D，E为叶子Future。Future C有D，E两个子Future，
因此Future C值的获得依赖于D，E值的获得，而最终大Future值的获得需要图中所有Future都获得返回值。
这种模式同时契合程序员编写异步代码的思维习惯。比如实现一个复制文件的功能，我们需要先从一个文件中读取数据，
然后再写入到另一个文件当中，这时候如果把读操作和写操作分别看作是一个Future的话，那么读Future和写Future就是
两个叶子Future，而整个“复制文件”任务就是一个大Future。因此，在Rust异步编程中，一个异步任务往往是由一个或多个
Future组成的。\par

\subsubsection{async/await语法糖}
上节提到Future的组合性，多个子Future可以组合成一个大Future，并且不难想象这种组合需求在编写代码中是很常见的。
但是Future表示的是一个将来值，怎么才能在代码里面将它们组合起来呢？\par

早期的方案是通过回调函数解决的。比如有两个Future A，B，
其中B依赖于A的返回值，想要实现A->B的Future组合子，就在B结构体里面保存一个回调函数，
这个函数以A的返回值为参数，执行后将会返回B的返回值。当Future A的值返回了，就调用该回调函数，
将该函数的返回值作为Future B的返回值返回。回调函数在这里起到了\textbf{延迟执行}的作用。\par

Rust，JavaScript等语言现在依然保留这种回调方案，但大部分情况下都不建议使用它，理由是：
\begin{enumerate}
  \item 回调函数代码本身的可维护性极低，复杂项目中很可能找不到某个回调函数对应哪个Future；
  \item 一旦子Future的数量较大，容易形成很长很长的回调链路，形成“回调地狱”；
  \item 在Rust中，由于语言特性的问题，使用回调函数容易出现不必要的内存拷贝，降低效率。
\end{enumerate}

async/await正是为了解决上述问题而被提出的另一种方案，
它们解决了传统异步编程的诸多痛点，同时能让开发者像写同步代码一样编写异步代码，
极大地降低了异步程序开发的难度。
这也是Rust 2018版本稳定了async/await语法后，
Rust社区正式统一了协程标准，并且Rust异步编程成为系统编程领域的一大杀器的原因。

async/await的主要作用是可以通过编译器生成Future：
\begin{itemize}
  \item 当一个函数或函数块被用async关键字修饰时，它的返回值会被编译器转换成Future；
  \item await关键字只能用于async函数或函数块中，并且作用对象只能是Future;
  \item await关键字的作用是调用子Future中的poll方法，并将结果（Ready/Pending）传递给大Future；
\end{itemize}

举个例子：
\begin{lstlisting}
  struct A {}
  struct B {}
  impl Future for struct A {...}
  impl Future for struct B {...}

  async foo() {
    let a = A.await;
    let b = b.await;
  }
\end{lstlisting}

经过async关键字修饰后，foo函数的返回值就变成了一个大Future（假设为Foo），它由两个子Future A，B组成，
它们之间的组合关系是A->B->Foo。编译器通过生成状态机代码来实现这种组合关系。\par

\subsubsection{执行器Executor}
协程被称为用户态线程，意味着需要有用户态的调度器来调度协程。在Rust中，同样需要一种协作式的调度管理机制，
在用户态管理和运行异步任务。负责这个工作的组件，被称为Executor（执行器）。\par

Rust中协程通常被称为异步任务，异步任务通常是一个由多个子Future组合成的大Future，当存在多个异步任务的时候，
就回到了如何调度并运行多个协程的问题。\par

通常情况下会存在一个就绪队列和一个等待队列，Executor的执行算法如下：
\begin{enumerate}
  \item 从就绪队列中弹出一个异步任务，调用其的poll方法：
    \begin{itemize}
      \item 若返回Ready，表示该异步任务已经完成，重复1操作；
      \item 若返回Pending，则将该异步任务放入等待队列，重复1操作。
    \end{itemize}
  \item 当就绪队列为空：
    \begin{itemize}
      \item 若等待队列不为空，阻塞直到等待队列中有新的异步任务被唤醒，放入到就绪队列，然后重复1操作；
      \item 若等待队列为空，所有异步任务已经完成，Executor退出。
    \end{itemize}
\end{enumerate}

\subsubsection{唤醒器Waker}
\textbf{Waker}（唤醒器）主要用于唤醒异步任务。\par

Waker和Future通常是一一绑定的关系，在上一小节就绪队列和等待队列的语境下，Waker的工作主要是
将其绑定的Future从等待队列移动到就绪队列，以此来唤醒Future。\par

\subsubsection{驱动器Reactor}
Reactor（驱动器）也被称为反应器，主要作用是根据发生的事件，比如I/O完成事件，来驱动异步任务的唤醒。\par

Waker通过Context参数传递给Future的poll方法，每个Future都应该在进行poll调用时，将Context中的Waker注册到
Reactor中，这样Reacotr才能够在事件来临时唤醒相应的Future。\par

\subsubsection{Rust异步编程架构}
以架构图总结一下Rust异步编程：

\cfig{rust-async}{0.9}{Rust异步架构}

\subsection{C++语言中的协程}
在C++ 20之前，C++语言本身不支持协程。开发者只能通过第三方库来获得协程支持，比如微信团队开源的有栈协程库libco。\par

C++ 20推出了无栈协程标准，标准里提供了co\underline{~}await等关键字
用于异步编程。从本质上看，C++ 20的协程和Rust里的协程是一样的，均为通过状态机实现的无栈协程。\par

由C++ 20协程引入的新概念主要是承诺类型Promise，Awaitable接口和三个新关键字：co\underline{~}await，co\underline{~}yield，
co\underline{~}return。下面将通过这些概念介绍和分析C++ 20的协程。\par

\subsubsection{承诺类型Promise}

在C++中协程被看成是可以挂起和恢复的函数，作为协程的函数的返回值必需包含\textbf{Promise}结构体。\par

Promise主要包含以下方法：

\begin{enumerate}
  \item get\underline{~}return\underline{~}object：用于返回当前协程的句柄；
  \item initial\underline{~}suspend：指定在协程初始化时是否立马挂起；
  \item final\underline{~}suspend：指定在协程即将结束时是否挂起；
  \item return\underline{~}value：获取协程的最终返回值；
  \item unhandled\underline{~}exception：处理协程中被抛出的异常。
\end{enumerate}

当一个协程结束后，可以通过它的句柄获得最终返回值。\par

\subsubsection{Awaitable接口}

C++中的Awaitable接口本质上等同于Rust中的Future接口，只是在细节上有所不同。
Awaitable接口主要包含以下方法：

\begin{enumerate}
  \item await\underline{~}ready：返回值为布尔类型，false表示该值没准备好，协程需要挂起，
    接着调用2，等同于Future的Pending；true为该值已准备好，接着调用3，等同于Future的Ready；
  \item await\underline{~}suspend：在1中返回false时调用，主要处理在协程被挂起前的准备工作；
  \item await\underline{~}resume：在1中返回true时或者协程恢复时调用，返回该Awaitable对象的值。
\end{enumerate}

在C++中，如果一个对象实现了Awaitable接口，那么这个对象就变成了一个将来值，等同于Rust中的Future。\par

\subsubsection{co\underline{~}await}
在C++中，co\underline{~}await关键字起到的作用和Rust中的await一致。
Rust中await的对象必须是Future，而C++中co\underline{~}await的对象必须是Awaitable对象。\par

C++编译器比如gcc会根据协程中co\underline{~}await的位置生成状态机代码实现无栈协程。\par

\subsubsection{co\underline{~}return}

co\underline{~}return 后面跟的表达式的值会作为参数传递给Promise中的return\underline{~}value方法，
用于返回整个协程的值。\par

\subsubsection{C++异步与Rust异步对比}

\begin{generaltab}{C++异步vsRust异步}{tbl:hmm}
  \begin{tabular}{c|ccc}
    \toprule
    -- & C++ & Rust \\
    \midrule
    协程称呼 & Coroutine & 异步任务 \\
    协程类型 & 无栈协程 & 无栈协程 \\
    将来值接口 & Awaitable & Future \\
    协程挂起点 & co\underline{~}await指定 & await指定 \\
    是否支持多次挂起 & 否 & 是 \\
    协程恢复方式 & 对协程句柄调用resume() & 对Future调用poll() \\
    \bottomrule
  \end{tabular}
\end{generaltab}

\subsection{异步编程框架}

经过上面的介绍，我们对异步I/O和Rust/C++协程有了初步的了解。接下来将进入本文的正题：
设计和实现高性能的异步编程框架。\par

什么是异步编程框架？前面介绍的无论是异步I/O还是协程的概念，都是比较偏系统底层的，
要想正确理解和使用它们，需要开发者具备完整的操作系统和编译原理的知识体系。
然而，许多应用开发者并不具备这样的能力，他们更多关注数据结构，算法和业务逻辑。
在现代软件开发领域中，分层设计已成共识，因此要想一般应用开发者也能比较轻松地利用到异步I/O和协程的高性能，
需要一个封装了异步I/O和协程概念，并向上层应用提供简单易用API的底层框架，这就是异步编程框架。\par

\subsection{本章小结}

本章我们首先从异步I/O入手，讨论了异步I/O与同步I/O的区别和性能优势；接着介绍了Linux平台上新增的io\underline{~}uring
异步接口；然后以线程切换开销大为切入点，引出协程并介绍了协程在性能上的优势，同时对比分析了线程与协程；
随后介绍了协程的分类和它们之间的区别；此外还详细介绍了Rust/C++中的协程实现；最后说明了异步编程框架的概念。\par

下一章我们将进入正题，介绍和分析毕设项目的整体系统设计。\par

\section{系统设计}
上一章介绍了io\underline{~}uring，协程和异步编程框架的基本概念。在目前开源软件生态中，
缺乏同时兼顾性能和易用性的开源异步编程框架。因此我们将基于io\underline{~}uring和协程，
分别使用Rust和C++语言设计并实现一款简单易用的高性能异步编程框架，
在贡献开源生态的同时，验证异步I/O和协程的可行性与高效性。\par

\subsection{功能需求}

\begin{enumerate}
  \item 底层封装。对io\underline{~}uring和协程进行封装，在不向上暴露两者细节的同时，提供高性能接口；
  \item 接口易用。向上提供用于构建网络应用和存储应用所需的简单易用的功能接口，例如TCP协议的连接；
  \item 安全。框架需确保稳定可靠，不允许出现内存泄漏，死锁等问题；
  \item 高性能。框架需要比目前主流的一些异步编程框架具备更高的性能。
\end{enumerate}

\subsection{系统总体设计}

我们采用分模块的系统设计方法，将整个异步编程框架划分为以下几个模块：

\begin{itemize}
  \item I/O操作基本单元\textbf{Op}；
  \item io\underline{~}uring对象\textbf{IoUring}；
  \item 异步任务\textbf{Task};
  \item 任务调度器\textbf{Scheduler};
  \item 事件驱动模块\textbf{Reactor}；
  \item 任务执行模块\textbf{Executor}；
\end{itemize}

它们之间的关系如\rfig{system-design}：\par

\cfig{system-design}{0.9}{系统设计架构图}

每个模块之间的关系应是独立解耦的，它们各自完成自己负责的工作，
而互不干扰。模块解耦的设计既能带来代码编写和维护上的便利，
同时也能增强整个系统的稳定性。\par

此外，从应用视角来看，可以增加两个功能模块：

\begin{itemize}
  \item 文件操作模块；
  \item 网络操作模块。
\end{itemize}

这两个模块的主要功能是生成应用相关的异步任务，比如TCP连接任务。
向上层应用提供简单易用的功能接口，则主要是这两个模块的工作。\par

在上述的模块当中，只有文件，网络操作模块为公开给外部的模块。
基于以上设计，我们可以看到io\underline{~}uring和协程的概念被封装到了
Op，IoUring，Executor等私有模块当中，向外暴露的只有文件，网络操作等与
应用相关的模块及其接口，从而实现我们的“底层封装”需求。\par

\subsection{功能模块设计}
本节将对系统设计中的各个模块进行详细介绍。\par

\subsubsection{Op模块}

Op在本系统设计中指代I/O相关操作的基本单元，从面向对象角度考虑它可以被理解为所有
I/O操作的\textbf{基类}。\par

在Linux平台上，存在非常多的I/O操作，比如read(2)，write(2)，recv(2)等。
如果不对它们进行统一抽象，在代码实现的时候将需要编写许多重复代码。\par

而对于异步I/O接口io\underline{~}uring来说，不同I/O操作之间的区别仅仅在于
它们往请求队列中提交的请求（SQE）中的数据不同。因此，采用面向对象的程序设计思想，
我们定义一个名为Op的基类，基于这个基类可以派生出各种子类，
这些子类则对应于Linux平台上的各种I/O操作。\par

Op模块需要实现的功能包括：

\begin{enumerate}
  \item 创建I/O请求SQE；
  \item 往io\underline{~}uring的提交队列中提交SQE；
  \item 在提交SQE后挂起当前协程；
  \item 在协程恢复后获得I/O操作的返回值。
\end{enumerate}

可以通过重写上述（1）中的功能达到派生子类的效果。\par

\subsubsection{IoUring模块}

IoUring在本系统设计中指代io\underline{~}uring的实例，
从面向对象的角度考虑它可以被理解为一个提供io\underline{~}uring相关操作接口的类。
比如Op需要往提交队列中提交请求，这时候它需要调用IoUring中的方法。\par

IoUring模块需要实现的功能包括：

\begin{enumerate}
  \item 提供初始化io\underline{~}uring实例的接口；
  \item 提供提交I/O请求的接口；
  \item 提供返回I/O完成事件CQE的接口。
\end{enumerate}

上述接口（1）用于初始化io\underline{~}uring环境，接口（2）用于Op模块提交SQE，
接口（3）用于Reactor模块收割CQE。\par

\subsubsection{Task模块}

Task在本系统设计中指代异步任务，或者协程，是Scheduler模块调度和Executor模块执行的基本单位。
在Rust语言中，Task通常为一个Future；在C++语言中，Task通常为一个协程。\par

Task可以由一个或多个Op的派生子对象组成。举个例子，假设Open和Read均为Op的派生子类，
分别表示打开文件和读文件的I/O操作，那么一个读文件的Task就可以表示为\rfig{read-file}：

\cfig{read-file}{0.4}{读文件Task}

Task模块需要实现的功能包括：

\begin{enumerate}
  \item 提供创建Task的接口；
  \item 提供挂起Task的接口；
  \item 提供恢复Task的接口；
  \item 提供获得Task返回值的接口。
\end{enumerate}

上述接口（1）用于创建异步任务或协程；接口（2）（3）分别用于Executor模块挂起和恢复异步任务或协程；
接口（4）用于获取一个异步任务完成时的返回值。\par

\subsubsection{Scheduler模块}

Scheduler在本系统设计中指代任务调度器，
主要负责内置调度算法，对异步任务或协程进行调度管理。
在后期性能优化中，调度算法也是关注点之一。\par

Scheduler模块需要实现的功能包括：

\begin{enumerate}
  \item 提供添加任务的接口；
  \item 提供弹出任务的接口，该接口以CQE作为参数。
\end{enumerate}

上述接口（1）用于添加异步任务或协程；接口（2）用于Reactor模块从IoUring模块获得CQE后，
以CQE为参数从调度器中弹出异步任务或协程。\par

\subsubsection{Reactor模块}

Reactor在本系统设计中指代事件驱动器，
主要负责轮询io\underline{~}uring实例中的完成队列，收割CQE，
并根据CQE唤醒对应的异步任务或协程。\par

Reactor模块需要实现的功能是：轮询调用IoUring模块的接口（3），
不断获取I/O完成事件CQE，并以CQE为参数调用Scheduler模块的接口（2），
弹出异步任务或协程，将其送到Executor模块中执行。\par

\subsubsection{Executor模块}

Executor在本系统设计中指代任务执行器，
主要负责接收异步任务或协程进行执行，恢复或挂起操作。\par

Executor模块需要实现的功能包括：

\begin{enumerate}
  \item 执行或恢复执行异步任务或协程，直到切换点（await/co\underline{~}await）；
  \item 若运行到切换点处时返回Pending或suspend，挂起当前异步任务或协程。
\end{enumerate}

上述接口（2）往往通过将异步任务或协程推入Scheduler模块实现挂起操作。\par

\subsubsection{文件，网络操作模块}

上面提到Task由一个或多个Op的派生子对象组成，而Op派生子类对应于Linux平台上的I/O操作。
Linux平台上的诸多I/O操作大体可以分为两部分：文件和网络。
文件操作包括打开文件（open(2)），读文件（read(2)）和写文件（write(2)）等等；
网络操作包括监听（listen(2)），连接（accept(2)）和接收字节流（recv(2)）等等。\par

本系统设计中的文件，网络操作模块主要负责生成各种Op派生子对象，
用于构建异步任务或协程，并且通过这种方式，向上层应用提供简单易用的异步接口。\par

文件，网络操作分别需要提供的接口如下：

\begin{generaltab}{异步文件/网络接口}{tbl:hmm}
  \begin{tabular}{c|ccc}
    \toprule
    文件 & 网络 \\
    \midrule
    打开文件 & 监听地址和端口 \\
    读文件 & 处理TCP连接 \\
    写文件 & 接收字节流 \\
    关闭文件 & 发送字节流 \\
    ... & ... \\
    \bottomrule
  \end{tabular}
\end{generaltab}

我们可以说文件，网络操作模块为应用层模块。\par

\subsection{设计中考虑的制约因素}

\textbf{社会因素考量}：在本文提出的异步编程框架的设计方案中，将提供简单易用的API列为需要实现的
功能需求点之一，降低了企业或者个人进行技术升级的人力成本，有利于社会生产力的提高。\par

\textbf{安全因素考量}：我们的方案充分考量了安全因素，在我们的方案中，不存在涉及网络安全相关的
因素，保证了实现的框架的安全。\par

\textbf{法律风险规避}：方案的设计和实现过程均进行了法律上的考量，项目依赖的软件库，开发过程使用的
开发工具和测试环节使用的测试工具，均为正版，免费版本和遵守开源协议的开源版本，
规避了侵权相关的法律问题。\par

\textbf{文化风险规避}：在方案设计和项目实现过程中，保证了对代码和文档的审查，
代码和文档中不存在不当言论，不存在暴力，低俗，反动，种族歧视等性质的词汇或语句，
确保整个项目不会产生文化风险。\par

\subsection{成本估算}

本毕设的成本估算选用Putnam模型。\par

在整个毕设开发过程中，编写源代码4997行，持续开发时间为0.4年，技术状态为好，
估算到开发工作量为9.520。\par

\subsection{本章小结}

本章我们首先从需求入手，首先讨论了异步编程框架设计中的功能需求；
接着从整体介绍了系统的架构设计和该设计如何满足需求；随后详细介绍了各功能模块的职责和需要实现的功能或
需要提供的接口；然后分析了设计中考虑的制约因素；最后估算了开发过程所花的成本。\par

\section{系统实现}

在上一章中我们进行了对异步编程框架的需求分析和整体系统设计，
本章将会分模块地详细介绍系统的具体实现。\par

在本毕设中，我们分别通过Rust语言和C++语言进行了系统实现，
完成了两套异步编程框架，分别名为\textbf{Emma}（Rust）和\textbf{Kuro}（C++）。\par

\subsection{Op模块实现}
\subsubsection{Rust中的实现}
在上一章提到，Op是所有io\underline{~}uring相关I/O操作的基类。
然而，在Rust中没有面向对象编程的概念，因此这里通过\textbf{泛型}来模拟面向对象的思想。\par

Rust中的泛型类似于C++中的模版（template）。泛型可以理解为类型的通配符，
通过泛型可以实现编译期的\textbf{多态}。比如，结构体A<T>表示结构体A具有泛型参数T，
T可以是任何类型，结构体A实例化的时候需要指定T的类型。
此外，可以为泛型添加约束，假设B是一个接口，则A<T: B>中的T类型必须实现了B接口，
否则编译器会报错。\par

基于以上讨论，Rust中Op模块的实现步骤为：

\begin{enumerate}
  \item 定义一个接口SubOp，这个接口中只有一个方法create\underline{~}sqe，
    用于创建I/O请求SQE；
  \item 定义一个泛型结构体Op<T: SubOp>，其中T受到接口SubOp的约束，
    必须实现create\underline{~}sqe方法；
  \item 为结构体Op<T: SubOp>实现Future接口，该接口中唯一的poll方法的具体实现逻辑为：
    \begin{itemize}
      \item 调用类型T的create\underline{~}sqe方法，创建SQE；
      \item 将SQE通过IoUring模块提供的接口提交到io\underline{~}uring的提交队列中，
        然后返回Pending，挂起当前协程；
      \item 当协程恢复时，从CQE中获取io\underline{~}uring返回值，并返回给调用方。
    \end{itemize}
  \item Op的子类通过实现SubOp接口来达到继承Op基类的效果。
\end{enumerate}

\subsubsection{C++中的实现}

C++中支持面向对象思想，因此可以直接基于面向对象的编程方法进行Op模块的实现。\par

C++中Op模块的实现步骤为：

\begin{enumerate}
  \item 定义一个基类Op；
  \item 定义一个Op中的成员方法create\underline{~}sqe，用于创建I/O请求SQE；
  \item 为基类Op实现Awaitable接口：
    \begin{itemize}
      \item await\underline{~}ready方法：直接返回false；
      \item await\underline{~}suspend方法：先调用create\underline{~}sqe成员方法获得SQE，
        然后将该SQE通过IoUring模块的接口提交到提交队列中，接着返回；
      \item await\underline{~}resume方法：当调用该方法时，已经从IoUring模块中得到了
        和await\underline{~}suspend中提交的SQE对应的CQE，因此直接返回CQE中的结果。
    \end{itemize}
  \item 为基类Op实现了Awaitable接口后，即为其实现了挂起当前协程的能力；
  \item Op的子类可以通过重写create\underline{~}sqe方法实现对Op基类的继承。
\end{enumerate}

\subsection{IoUring模块实现}

\subsubsection{Rust中的实现}

在Rust中，我们用到一个第三方库\textbf{io-uring}来实现IoUring模块。\par

io-uring是一个对io\underline{~}uring相关底层接口进行封装的Rust第三方库，
它提供一个IoUring结构体，同时为这个结构体实现了一系列方法用于对io\underline{~}uring实例进行操作。\par

基于io-uring库实现IoUring模块的步骤为：

\begin{enumerate}
  \item 引用io-uring库的IoUring结构体；
  \item 使用IoUring结构体的new方法作为初始化io\underline{~}uring实例的外部接口；
  \item 使用IoUring结构体的submitter方法作为提交I/O请求的外部接口；
  \item 使用IoUring结构体的completion方法作为返回I/O完成事件CQE的外部接口。
\end{enumerate}

\subsubsection{C++中的实现}

在第二章提到，io\underline{~}uring的作者编写了一个用户态库\textbf{liburing}，
它是一个和Rust中io-uring库同等性质的C语言第三方库，封装了io\underline{~}uring相关的底层接口。\par

在C++中，我们使用liburing库实现IoUring模块：

\begin{enumerate}
  \item 引用liburing库的io\underline{~}uring结构体；
  \item 使用liburing库提供的io\underline{~}uring\underline{~}queue\underline{~}init函数作为
    初始化io\underline{~}uring实例的外部接口；
  \item 使用liburing库提供的io\underline{~}uring\underline{~}submit函数作为提交I/O请求的外部接口；
  \item 使用liburing库提供的io\underline{~}uring\underline{~}for\underline{~}each\underline{~}cqe
    宏函数作为返回I/O完成事件CQE的外部接口。
\end{enumerate}

\subsection{Task模块实现}

\subsubsection{Rust中的实现}

在Rust中，Task等同于异步任务，而在第二章介绍过Rust里面异步任务通常是一个大Future，
由一个或多个子Future组成，async/await关键字能帮助我们创建大Future。\par

因此，在Rust中Task模块的实现步骤为：

\begin{enumerate}
  \item 使用async关键字创建Task；
  \item 使用await关键字挂起Task；
  \item 通过对Task调用Future接口中的poll方法来恢复Task；
  \item Task运行结束后从Future接口中的poll方法的返回值获取整个Task的返回值。
\end{enumerate}

\subsubsection{C++中的实现}

在C++中，Task等同于协程。在第二章中介绍过C++中协程被看成是可以挂起和恢复的函数，
作为协程的函数的返回值必需实现Promise接口。\par

因此，在C++中Task模块的实现步骤为：

\begin{enumerate}
  \item 定义一个模版类Task<T>；
  \item 为Task<T>实现Promise接口：
    \begin{itemize}
      \item get\underline{~}return\underline{~}object方法：通过this指针构造协程句柄，
        然后将此句柄返回；
      \item initial\underline{~}suspend方法：直接返回suspend\underline{~}never；
      \item final\underline{~}suspend方法：直接返回suspend\underline{~}never；
      \item return\underline{~}value方法：该方法会传入T类型的参数v，将v拷贝到Task<T>中。
    \end{itemize}
  \item 为Task<T>实现Promise接口后，返回值为Task<T>的函数均被作为协程看待，
    因此调用此类函数即可创建Task；
  \item 在返回值为Task<T>的函数中使用co\underline{~}await关键字来挂起Task；
  \item 通过调用协程句柄的resume方法来恢复Task；
  \item 当协程运行到co\underline{~}return关键字处时，其后面跟的值会被作为参数调用Promise接口
    中的方法return\underline{~}value，因此该值会被保存在Task<T>对象中。
    当协程运行结束后，可以从Task<T>对象中获取返回值。
\end{enumerate}

\subsection{Scheduler模块实现}

针对Scheduler模块，Rust和C++实现中都使用到了一种名为\textbf{Slab}的数据结构。
Slab是一种内存分配器，它通过预先申请固定大小的内存，减少调用方申请内存空间的次数，
提高性能。\par

Slab提供的外部接口如下：

\begin{enumerate}
  \item new方法：创建固定大小的Slab；
  \item capacity方法：返回容量；
  \item len方法：返回当前长度；
  \item insert方法：插入一个元素，并返回一个token；
  \item get方法：通过token获取元素引用；
  \item remove方法：通过token弹出元素。
\end{enumerate}

此外，在第二章介绍io\underline{~}uring提到，用户可以通过往提交队列添加SQE来提交I/O请求和从完成队列收割CQE
来获取I/O完成事件，但在完成队列中CQE不是按序到达的，这样一来如何直到CQE对应哪个SQE呢？事实上，
SQE和CQE中都有个名为user\underline{~}data的字段，该字段不会被操作系统内核修改，它是用户在SQE中传入的，
并且会被原封不动地在CQE中返回给用户，用于识别该CQE对应于哪个SQE。\par

因此，在Rust和C++中Scheduler模块的实现步骤均为：

\begin{enumerate}
  \item 使用Slab数据结构保存Task模块；
  \item 通过调用Slab的insert方法来实现添加任务接口，这时候insert函数调用返回一个token；
    接着把这个token注册到CQE中；
  \item 通过Slab的remove方法实现弹出任务接口：
    \begin{itemize}
      \item 外部模块调用此接口时，会传入一个CQE参数；
      \item 使用CQE中的user\underline{~}data字段作为token调用remove方法，弹出任务。
    \end{itemize}
\end{enumerate}

\subsection{Reactor模块实现}

在Rust和C++中，Reactor模块的实现步骤均为：

\begin{enumerate}
  \item 在一个大循环中，不断轮询调用IoUring模块的获取CQE的接口；
  \item 在循环体中，获取到CQE后，以CQE为参数从Scheduler模块中弹出任务Task；
  \item 以Task为参数调用Executor模块执行任务的接口。
\end{enumerate}

\subsection{Executor模块实现}

\subsubsection{Rust中的实现}

在Rust中，Executor模块的实现步骤为：对Task调用Future接口中的poll方法，
若返回Pending，则调用Scheduler模块的添加任务接口，
将该Task重新放入到Scheduler模块中，即将Task挂起；
若返回Ready，则表示Task运行结束，这时候把CPU控制权让给其他模块，
等待Reactor模块的下一次调用。\par

\subsubsection{C++中的实现}

在C++中，Executor模块的实现步骤为：对Task调用resume方法，
当运行到co\underline{~}await处并需要挂起协程时，执行流会直接返回到调用resume方法的下一行，
这是C++编译器做的工作；当resume方法运行完成时，表示该Task运行结束，
这时候同样将CPU控制权让给其他模块，等待Reactor模块的下一次调用。\par

\subsection{文件，网络操作模块实现}

在第三章系统设计中介绍到，文件，网络操作模块用于向上层应用开发者提供异步文件和网络操作的接口，
此模块属于应用层模块。\par

基于整体的系统设计，文件，网络操作模块只需要生成Op基类的派生子对象，
并将其打包成Task添加到Scheduler模块中，即可完成异步接口的实现。
同时，继承Op基类的方法已经在Op模块的实现中指出，
因此文件，网络操作模块需要做的是基于不同的I/O操作类型，完成不同Op派生子类的实现。\par

举个例子，在C++中，实现异步读文件接口可以通过以下步骤：

\begin{enumerate}
  \item 定义一个名为\textbf{Read}的类，该类继承于Op基类；
  \item 重写Read类的create\underline{~}sqe方法，使得create\underline{~}sqe返回一个I/O读请求的SQE；
  \item 完成重写后，定义一个名为async\underline{~}read的函数，该函数返回一个Read对象，
    则async\underline{~}read就是一个异步读文件的接口。
\end{enumerate}

在实际使用的时候，在协程中使用co\underline{~}await async\underline{~}read()，
即可完成异步读文件接口的调用。\par

打开文件，写文件，接受TCP请求等异步I/O接口也能通过上述例子的步骤实现，
它们之间的区别仅仅是重写create\underline{~}sqe方法的方式不一样罢了，
这里不一一阐述。此外，在Rust中实现异步I/O接口的方式也和上面例子差不多，
区别仅在不是重写create\underline{~}sqe方法，而是实现SubOp接口罢了。\par

\subsection{本章小结}

本章主要详细介绍了系统中各个功能模块的具体实现方法。\par

\section{性能测试与分析}
上一章详细介绍了两套分别用Rust语言和C++语言实现的异步编程框架Emma和Kuro的具体实现。
在第三章需求分析环节中提到，高性能是我们的主要目标之一。
因此在本章，我们将对Emma和Kuro进行性能测试，
以此验证基于io\underline{~}uring和协程实现的异步编程框架具备高效性能。\par

\subsection{测试环境}
CPU：Intel(R) Xeon(R) Gold 5117 CPU @ 2.00GHz，56逻辑核，2物理核\par

网卡：Ethernet controller: Intel Corporation Ethernet Connection X722 for 10GbE SFP+ (rev 09)\par

操作系统：Linux ubuntu85 5.13.0-40-generic \#45-Ubuntu SMP Tue Mar 29 14:48:14 UTC 2022 x86\underline{~}64 x86\underline{~}64 x86\underline{~}64 GNU/Linux\par

% \subsection{功能测试}
% 功能测试主要注重于异步编程框架的功能实现是否正确。由于本毕设实现的框架提供的外部接口较多，
% 考虑到篇幅受限，因此重点选择较为常用的一些接口进行功能测试。\par
%
% 从应用视角将功能测试分为文件部分和网络部分。\par
%
% \subsubsection{文件功能测试}
% 文件部分主要对以下接口进行功能测试：
%
% \begin{enumerate}
%   \item 打开文件；
%   \item 读文件；
%   \item 写文件。
% \end{enumerate}
%
% 我们可以通过使用实现完成的异步编程框架Emma和Kuro编写一个复制文件的应用，即可完成以上接口的功能测试。\par
%
% \subsubsection{网络功能测试}
%
% 网络部分主要对以下接口进行功能测试：
%
% \begin{enumerate}
%   \item 监听指定的IP地址和端口；
%   \item 接受TCP连接；
%   \item 接收字节流；
%   \item 发送字节流。
% \end{enumerate}
%
% 我们可以通过使用完成的异步编程框架Emma和Kuro编写一个简易HTTP服务器，即可完成以上接口的功能测试。\par
%
% \subsubsection{分析}

\subsection{性能测试}

本次性能测试的主要目的是验证实现的异步编程框架的高性能，
因此我们使用实现的框架Emma和Kuro与当前开源生态中主流的一些异步编程框架进行对比实验，
这些主流框架包括：

\begin{itemize}
  \item Tokio；
  \item async-std；
  \item Go。
\end{itemize}

其中Tokio和async-std是基于Rust语言实现的异步编程框架，Go指Go语言原生支持的有栈协程框架。\par

此外，为了验证异步I/O和协程的高性能，我们会增加一组对照组：基于同步I/O和多线程的传统并发编程框架，
起名为\textbf{Sync}。\par

我们从应用视角将性能测试分为文件和网络两部分，每个部分都拥有独立的测试方法和结果分析。\par

\subsubsection{文件性能测试}

\subsubsubsection{测试方法}

使用参与性能测试的各框架编写一个文件操作的简单应用程序，该应用需要完成多个固定大小的文件的读写任务。\par

控制变量包括：

\begin{enumerate}
  \item 文件数量N；
  \item 文件大小M；
  \item CPU核数L。
\end{enumerate}

测试指标为时间开销T。\par

\subsubsubsection{测试结果}
以下实验结果均采用5次重复实验求平均值得出。\par

\begin{tikzpicture}
  \begin{axis}[
      title={M=1 KB, L=1},
      xlabel={Number of files(N)},
      ylabel={Cost of time [ms]},
      legend style={nodes={scale=0.7, transform shape}},
      legend pos=north west
    ]
    
    \addplot[color=red, mark=square]
    coordinates {
      (512,127.8)
      (1024,147.6)
      (1024*2,174.6)
      (1024*3,186.2)
      (1024*4,235.4)
      (1024*5,262.6)
      (1024*6,270.6)
      (1024*7,313)
      (1024*8,331.4)
    };
    \addlegendentry{Kuro}

    \addplot[color=black, mark=square]
    coordinates {
      (512,97.8)
      (1024,116.2)
      (1024*2,142.8)
      (1024*3,163)
      (1024*4,182.6)
      (1024*5,206.6)
      (1024*6,230.6)
      (1024*7,249.2)
      (1024*8,276.8)
    };
    \addlegendentry{Emma}

    \addplot[color=orange, mark=square]
    coordinates {
      (512,155.6)
      (1024,205.8)
      (1024*2,225.4)
      (1024*3,258.6)
      (1024*4,313.2)
      (1024*5,331.6)
      (1024*6,348.4)
      (1024*7,390.6)
      (1024*8,436.4)
    };
    \addlegendentry{Tokio}
    
    \addplot[color=green, mark=square]
    coordinates {
      (512,139.6)
      (1024,216.8)
      (1024*2,314.8)
      (1024*3,421.8)
      (1024*4,533.4)
      (1024*5,620)
      (1024*6,740.6)
      (1024*7,844.6)
      (1024*8,940.6)
    };
    \addlegendentry{async-std}
    
    \addplot[color=blue, mark=square]
    coordinates {
      (512,80.6)
      (1024,91.4)
      (1024*2,118.2)
      (1024*3,175)
      (1024*4,215.2)
      (1024*5,235.6)
      (1024*6,253.2)
      (1024*7,302.8)
      (1024*8,317.4)
    };
    \addlegendentry{Go}
    
    \addplot[color=purple, mark=square]
    coordinates {
      (512,21)
      (1024,34.2)
      (1024*2,56.6)
      (1024*3,79.6)
      (1024*4,101.2)
      (1024*5,120.6)
      (1024*6,144.4)
      (1024*7,166.4)
      (1024*8,186.6)
    };
    \addlegendentry{Sync}

  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[
      title={M=1 KB, L=32},
      xlabel={Number of files(N)},
      ylabel={Cost of time [ms]},
      legend style={nodes={scale=0.7, transform shape}},
      legend pos=north west
    ]
    
    \addplot[color=red, mark=square]
    coordinates {
      (512,122)
      (1024,156.2)
      (1024*2,178.6)
      (1024*3,179.8)
      (1024*4,180)
      (1024*5,189)
      (1024*6,194.2)
      (1024*7,195.6)
      (1024*8,197.8)
    };
    \addlegendentry{Kuro}

    \addplot[color=black, mark=square]
    coordinates {
      (512,93.6)
      (1024,90.2)
      (1024*2,101)
      (1024*3,107.2)
      (1024*4,104.2)
      (1024*5,113.4)
      (1024*6,112)
      (1024*7,119.6)
      (1024*8,112.4)
    };
    \addlegendentry{Emma}
    
    \addplot[color=orange, mark=square]
    coordinates {
      (512,171.8)
      (1024,209.2)
      (1024*2,284.8)
      (1024*3,348.4)
      (1024*4,437.2)
      (1024*5,495.4)
      (1024*6,577.4)
      (1024*7,654.8)
      (1024*8,750.2)
    };
    \addlegendentry{Tokio}

    \addplot[color=green, mark=square]
    coordinates {
      (512,139.6)
      (1024,216.8)
      (1024*2,314.8)
      (1024*3,421.8)
      (1024*4,533.4)
      (1024*5,620)
      (1024*6,740.6)
      (1024*7,844.6)
      (1024*8,940.6)
    };
    \addlegendentry{async-std}

    \addplot[color=blue, mark=square]
    coordinates {
      (512,80.6)
      (1024,91.4)
      (1024*2,118.2)
      (1024*3,175)
      (1024*4,215.2)
      (1024*5,235.6)
      (1024*6,253.2)
      (1024*7,302.8)
      (1024*8,317.4)
    };
    \addlegendentry{Go}

    \addplot[color=purple, mark=square]
    coordinates {
      (512,4)
      (1024,7)
      (1024*2,13)
      (1024*3,19)
      (1024*4,23)
      (1024*5,28)
      (1024*6,31)
      (1024*7,35)
      (1024*8,39)
    };
    \addlegendentry{Sync}

  \end{axis}
\end{tikzpicture}


\subsubsubsection{结果分析}

\begin{enumerate}
  \item 从测试结果中可以看到，无论是单核场景还是多核场景，
    我们实现的框架Kuro和Emma在异步文件读写上比Tokio，Go等目前主流的开源异步编程框架具有更好的性能。
    Kuro和Emma底层使用了io\underline{~}uring作为异步文件I/O接口，而其他框架底层使用线程池模拟等方式
    实现异步文件I/O，因此该测试结果验证了io\underline{~}uring接口的高性能；
  \item 从测试结果中我们发现，相比于单核场景，在多核场景下Kuro和Emma的性能有较大幅度提升，
    这表示我们实现的框架Kuro和Emma同样可以充分利用到现代CPU的多核架构，发挥更极致的性能；
  \item 此外我们发现，基于Sync框架，也就是同步I/O和多线程模式编写的文件读写测试用例在测试中获得了最高的性能，
    这和我们预想的不一样，似乎异步I/O和协程并不比同步I/O和线程高效。
    对此，我们猜想出现这样结果的原因如下：
    \begin{itemize}
      \item 读写文件的并发量和数据量不够，没能将服务器的磁盘I/O打满，这导致同步I/O没有因为等待数据而阻塞太长时间，
        很快便返回了；反观io\underline{~}uring这边，为了实现复杂的异步I/O接口，引入了一定开销，
        导致在对轻量I/O任务的执行效率上不及同步I/O；
      \item 在此测试用例中，没有创建太多线程，因此协程的切换开销小的性能优势没有体现出来。
    \end{itemize}
\end{enumerate}

\subsubsection{网络性能测试}

\subsubsubsection{测试方法}

使用参与性能测试的各框架编写一个简单的HTTP服务器应用，该服务器需要监听某个固定的IP地址和端口，
然后不断接受客户端发起的TCP连接请求。TCP连接建立后，客户端会发送POST请求给服务器，
服务器在读取请求的字节流后，需要将该字节流携带在HTTP报文里返回给客户端。
客户端收到HTTP响应后，一次HTTP请求任务完成。\par

控制变量包括：

\begin{enumerate}
  \item HTTP请求数N；
  \item 客户端数量C；
  \item CPU核数L。
\end{enumerate}

测试指标为服务器吞吐量（请求数/秒）；

我们使用Apache Benchmark（简称ab）工具来模拟多客户端的并发请求。
ab是Apache旗下的一个用于测试Web服务器性能的压力测试工具，
它基于多线程来模拟多个客户端同时对某一IP地址进行访问，对发压端机器的要求较低，
却能给目标服务器带来巨大的负载。\par

\subsubsubsection{测试结果}
以下测试结果均采用5次重复实验求平均值得出。\par

\begin{tikzpicture}
  \begin{axis}[
      title={C=20, L=54},
      xlabel={Number of requests(N)},
      ylabel={Throughput [requests per second]},
      legend style={nodes={scale=0.7, transform shape}},
      legend pos=north east
    ]
    
    \addplot[color=red]
    coordinates {
      (2000,1014.75)
      (4000,716.25)
      (6000,857.81)
      (8000,555.05)
      (10000,449.41)
      (12000,325)
      (14000,362.92)
      (16000,307.48)
      (18000,283.32)
      (20000,293.67)
    };
    \addlegendentry{Kuro}
  
    \addplot[color=black]
    coordinates {
      (2000,1088)
      (4000,674)
      (6000,722)
      (8000,783)
      (10000,307.58)
      (12000,375.45)
      (14000,303.54)
      (16000,348.05)
      (18000,284.63)
      (20000,294.31)
    };
    \addlegendentry{Emma}
    
    \addplot[color=orange]
    coordinates {
      (2000,993.34)
      (4000,762.11)
      (6000,684.81)
      (8000,350.44)
      (10000,350.68)
      (12000,310.33)
      (14000,289.6)
      (16000,307.30)
      (18000,284.48)
      (20000,294.51)
    };
    \addlegendentry{Tokio}

    \addplot[color=green]
    coordinates {
      (2000,745)
      (4000,710)
      (6000,694.98)
      (8000,491.11)
      (10000,268)
      (12000,269.29)
      (14000,335.21)
      (16000,292.36)
      (18000,277.43)
      (20000,293.38)
    };
    \addlegendentry{async-std}

    \addplot[color=blue]
    coordinates {
      (2000,278.65)
      (4000,280)
      (6000,285.5)
      (8000,65.63)
      (10000,35.68)
      (12000,79.89)
      (14000,68.74)
      (16000,71.35)
      (18000,64.78)
      (20000,68.78)
    };
    \addlegendentry{Go}

    \addplot[color=purple]
    coordinates {
      (2000,855)
      (4000,511)
      (6000,426)
      (8000,323.05)
      (10000,317.41)
      (12000,301.09)
      (14000,269.92)
      (16000,277.48)
      (18000,276.32)
      (20000,279.67)
    };
    \addlegendentry{Sync}

  \end{axis}
\end{tikzpicture}


\begin{tikzpicture}
  \begin{axis}[
      title={C=200, L=54},
      xlabel={Number of requests(N)},
      ylabel={Throughput [requests per second]},
      legend style={nodes={scale=0.7, transform shape}},
      legend pos=north east
    ]

    \addplot[color=red]
    coordinates {
      (2000,1848.60)
      (4000,1804.40)
      (6000,1817.68)
      (8000,860.36)
      (10000,513.02)
      (12000,496.14)
      (14000,468.13)
      (16000,401.29)
      (18000,607.912)
      (20000,410.65)
    };
    \addlegendentry{Kuro}

    \addplot[color=black]
    coordinates {
      (2000,1369.70)
      (4000,1405.72)
      (6000,1420.92)
      (8000,652.52)
      (10000,432.81)
      (12000,454.36)
      (14000,460.18)
      (16000,463.651)
      (18000,368.08)
      (20000,458.60)
    };
    \addlegendentry{Emma}

    \addplot[color=orange]
    coordinates {
      (2000,1419.75)
      (4000,1404.97)
      (6000,1400.10)
      (8000,569.01)
      (10000,336.44)
      (12000,403.31)
      (14000,380.33)
      (16000,325.14)
      (18000,404.63)
      (20000,368.56)
    };
    \addlegendentry{Tokio}

    \addplot[color=green]
    coordinates {
      (2000,1223.86)
      (4000,1119.30)
      (6000,825.98)
      (8000,569.42)
      (10000,369.17)
      (12000,370.69)
      (14000,343.11)
      (16000,406.91)
      (18000,363.45)
      (20000,378.93)
    };
    \addlegendentry{async-std}

    \addplot[color=blue]
    coordinates {
      (2000,61.39)
      (4000,60.24)
      (6000,69.99)
      (8000,71.19)
      (10000,74.03)
      (12000,59.66)
      (14000,68.39)
      (16000,69.24)
      (18000,58.75)
      (20000,63.64)
    };
    \addlegendentry{Go}

    \addplot[color=purple]
    coordinates {
      (2000,1037.15)
      (4000,1365.26)
      (6000,1368.78)
      (8000,377.95)
      (10000,366.30)
      (12000,333.49)
      (14000,290.28)
      (16000,278.81)
      (18000,263.93)
      (20000,274.68)
    };
    \addlegendentry{Sync}

  \end{axis}
\end{tikzpicture}

\subsubsubsection{结果分析}

\begin{enumerate}
  \item 从测试结果中可以看到，我们实现的框架Kuro和Emma在参与性能测试的各个异步编程框架中
    表现出了最好的性能。Kuro和Emma底层使用io\underline{~}uring作为异步网络I/O接口，
    而Tokio，async-std等框架底层使用epoll等机制，因此该测试结果验证了io\underline{~}uring
    比传统网络I/O接口具备更高的性能；
  \item 同时我们可以看到，随着请求数N的增大，服务器负载逐渐打满，各个框架实现的服务端程序的吞吐量均趋于一个恒定值。
    而Kuro和Emma的恒定值是最高的，因此可以验证在系统满负载的时候Kuro和Emma具备更高的稳定吞吐量；
  \item 对比C=20和C=200的测试结果，我们发现在并发数较大时，Kuro和Emma的性能优势更加明显，
    这同时验证了Kuro和Emma相比其他异步编程框架在高并发的场景具有更优秀的表现；
  \item 此外我们发现，和文件部分的性能测试中相反，基于同步I/O和多线程实现的服务端程序在网络部分的性能测试中
    表现较差，排在倒数第二，仅高于Go框架。
    我们对这个现象进行了以下分析：
    \begin{itemize}
      \item 数据在网络中传输往往比在磁盘上传输要慢，因此在网络部分的性能测试中同步I/O需要阻塞较长时间，
        而异步I/O不需要进行任何的数据等待，因此后者更为高效；
      \item 在高并发场景中，Sync框架需要对每个TCP连接创建一个线程去处理，而Kuro和Emma仅需要创建一个协程，
        因此该测试结果验证了协程是一种比线程更为轻量的并发编程模式。
    \end{itemize}
\end{enumerate}

\subsection{本章小结}
本章对实现的异步编程框架Kuro和Emma分别进行了文件部分和网络部分的性能测试，
通过和目前主流的开源异步编程框架进行对比实验，验证了Kuro和Emma还有io\underline{~}uring的高性能特点；
同时，通过和基于同步I/O和多线程模式编写的框架进行对比实验，验证了异步I/O和协程
在系统满负载，I/O数据需要等待较长时间的场景下，比同步I/O和线程具有更好的性能，
在系统压力较小，I/O数据较快返回的场景下，同步I/O更胜一筹。\par

\section{总结与展望}
异步I/O和协程是近年来逐渐在底层系统编程领域兴起的两个研究方向，
而异步编程框架则是两者在工程实践上的典型例子。通过异步编程框架，
应用软件开发者们可以在不具备完整操作系统和编译原理知识体系的前提下
利用到异步I/O和协程的高性能。同时，随着互联网用户体量的增加和5G技术的发展，
对于高效的I/O方案和支持高并发的服务端开发技术的需求越来越高，
高性能异步编程框架的价值将会越来越大。\par

本文首先以异步I/O和协程为基点，对io\underline{~}uring，有栈协程和无栈协程等背景技术进行了介绍。
接着从需求分析的角度，围绕底层封装，提供接口，安全可靠和高效性能四个方面着手进行了分析，
并讨论了整体系统的架构设计，以及分模块地对系统设计进行了介绍。
随后，针对系统设计中的每个模块，详细介绍了实现方法。
最后，本文对实现的两个异步编程框架Kuro和Emma进行了性能测试，并完成了对测试结果的分析说明。\par

从性能测试结果中看到，实现的异步编程框架Kuro和Emma在性能方面表现不俗，功能实现正常，
下一步的工作将从以下方面进行：

\begin{enumerate}
  \item \textbf{完善更多功能}，尽管目前Kuro和Emma支持了大部分的异步I/O接口，但仍然存在一些
    高级功能还有待完善；
  \item \textbf{更规范的性能测试}，在本文的性能测试环节中，存在一些可能对实验结果产生影响的因素，
    比如网络带宽，文件块缓存等等，下一步工作中可以尝试构建更规范，更标准的测试环境进行测试，
    获得更准确的结果；
  \item \textbf{系统实现细节的优化}，在Kuro的Emma的实现过程中，我们发现了许多性能优化点，
    比如Scheduler模块的调度算法，但由于时间原因没有完成，
    下一步工作中可以尝试深度优化一下实现细节。
\end{enumerate}


\begin{thankpage}

本毕业设计从最开始立项到完成框架的代码编写再到最后完成性能测试前前后后一共用了大概四个月的时间。
在这段时间里，外界给予了我很多帮助和鼓励，使我能坚持完成整个毕业设计任务，
同时我也从毕设过程中得到了成长。\par

首先要感谢我的校内导师邵志远老师。邵老师在毕设前期提出了许多宝贵的意见，在研究方向和研究价值上
给了我指引；在毕设中期时负责任地对我的毕业设计进度进行检查，
并提醒我要注重成果表述和论文写作；在毕设后期提供服务器账号帮助我完成性能测试。
再次感谢邵志远老师对我的开题报告，文献翻译和毕业论文的仔细阅读和提出的修改意见。\par

其次，我还要感谢我的校外导师，清华大学的陈渝老师。陈渝老师大四上学期就十分关心我对于毕设的想法，
我们经常在周四的组会上交流和讨论毕设的进展。正是陈渝老师的关注让我充满动力，
最终完成项目代码和毕业论文的编写。\par

接着，感谢18级校际交流1班的全体同学。在大学的四年里，我很少参与校园内的娱乐活动，
平日里不是在教学楼里上课，在实验室做实验，就是呆在寝室里做喜欢的事情，
而和我交流最多的就是班级同学。和你们的交流，为我带来了快乐。\par

此外，感谢开源社区。在我的毕设项目中，引用了许多开源项目，开源社区减轻了我的许多工作量。
同时，参与开源社区使我感到快乐，通过开源，我编写的代码不再是一行行冰冷的英文字母，
而是能和其他开源作者交流的艺术作品，这让我收获了成就感。\par

最后，感谢一下我自己。从大一进入校园，后面通过转专业考试进入计算机学院，
接着通过大大小小的专业课程考试，
再到拿到心仪的offer，最终完成毕业论文，一路上的颠沛流离只有自己清楚。
希望在毕业之后，自己踏上社会后，能不忘初心，一直追求自己的理想。\par

再次，向在人生道路上给予我帮助的人们表示衷心的感谢！\par

\end{thankpage}

\nocite{*}

\bibliography{thesis}
  % \bibitem{ref1}Conway, Melvin E. Design of a Separable Transition-diagram Compiler. Communications of the ACM (ACM). July 1963, 6 (7): 396–408. ISSN 0001-0782. doi:10.1145/366663.366704 –via ACM Digital Library.

\end{document}
